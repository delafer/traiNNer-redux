# yaml-language-server: $schema=https://raw.githubusercontent.com/the-database/traiNNer-redux/refs/heads/master/schemas/redux-config.schema.json
# Stage 2C: ParagonSR2 Nano 2x Perceptual - Non-EMA sharp, stable finetune
# - Start from best Stage 1 non-EMA pretrain
# - Emphasis on crisp, clean, visually pleasing outputs
# - Avoid EMA softness and heavy GAN artifacts; controlled perceptual + consistency + frequency + light R3GAN
# Notes:
# - L1 remains dominant to preserve fidelity.
# - Perceptual + DISTS are moderate for pleasing details.
# - Consistency prevents color/gamma drift.
# - FFL adds crispness.
# - R3GAN is intentionally minimal to avoid painterly or crunchy artifacts.
# - EMA is conservative; select final export after visually comparing EMA vs non-EMA.

name: 2x_ParagonSR2_Nano_Perceptual_Stage2C
scale: 2

# Use modern training features for speed & stability; all are deployment-safe.
use_amp: true
amp_bf16: false
use_channels_last: true
fast_matmul: true
num_gpu: auto

# -------------------------------------------------------------------------------------------------
# Data (same dataset paths as Stage 1 pretrain, but smaller patch for perceptual finetune)
# -------------------------------------------------------------------------------------------------
datasets:
  train:
    name: Train_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/lr_x2
    lq_size: 64
    use_hflip: true
    use_rot: true
    num_worker_per_gpu: 8
    batch_size_per_gpu: 8
    accum_iter: 1

  val:
    name: Val_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_x2

# -------------------------------------------------------------------------------------------------
# Network
# -------------------------------------------------------------------------------------------------
network_g:
  type: paragonsr2_nano

network_d:
  type: munet

# -------------------------------------------------------------------------------------------------
# Paths
# -------------------------------------------------------------------------------------------------
path:
  # Use non-EMA Stage 1 pretrain as requested.
  pretrain_network_g: /home/phips/Documents/GitHub/traiNNer-redux/experiments/2x_ParagonSR2_Nano_Pretrain/models/resume_models/net_g_200000.safetensors
  strict_load_g: true
  resume_state: ~

# -------------------------------------------------------------------------------------------------
# Training
# -------------------------------------------------------------------------------------------------
train:
  # Conservative EMA to keep stability while avoiding strong EMA softness.
  ema_decay: 0.995
  ema_power: 0.75
  grad_clip: true

  optim_g:
    type: AdamW
    lr: !!float 5e-5
    weight_decay: 0.0
    betas: [0.9, 0.99]

  optim_d:
    type: AdamW
    lr: !!float 5e-5
    weight_decay: 0.0
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [40000, 60000]
    gamma: 0.5

  total_iter: 80000
  warmup_iter: 2000

  # ---
  # Losses: clean, controlled stack
  # Schema note:
  # - Only built-in loss types are validated by JSON schema.
  # - Custom repo losses (convnextperceptualloss, ConsistencyLoss, ContrastiveLoss, etc.)
  #   may show editor schema warnings but are supported by traiNNer-redux.
  # ---
  losses:
    # Fidelity anchor
    - type: l1loss
      loss_weight: 1.0

    # Very light MSSIM (set to 0.0 or comment out if you prefer to disable)
    - type: mssimloss
      loss_weight: 0.05

    # Perceptual (ConvNeXt-based)
    - type: convnextperceptualloss
      loss_weight: 0.18

    # DISTS for perceptual similarity
    - type: distsloss
      loss_weight: 0.15

    # Consistency: stabilize color/brightness; prevent perceptual/GAN drift
    - type: ConsistencyLoss
      loss_weight: 0.08
      criterion: chc
      blur: false
      saturation: 1.0
      brightness: 1.0
      cosim: true
      cosim_weight: 0.5

    # Optional light contrastive; keep very small
    - type: ContrastiveLoss
      loss_weight: 0.05
      temperature: 0.1

    # Frequency sharpening (moderate)
    - type: ffloss
      loss_weight: 0.12

    # Very light R3GAN for subtle "pop"
    - type: ganloss
      gan_type: r3gan
      loss_weight: 0.015
      r1_weight: 2.5
      r2_weight: 2.5

# -------------------------------------------------------------------------------------------------
# Validation
# -------------------------------------------------------------------------------------------------
val:
  val_enabled: true
  val_freq: 5000
  save_img: true

  metrics_enabled: true
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 2
      test_y_channel: false
    ssim:
      type: calculate_ssim
      crop_border: 2
      test_y_channel: false
    lpips:
      type: calculate_lpips
      better: lower
    dists:
      type: calculate_dists
      better: lower
    topiq:
      type: calculate_topiq

# -------------------------------------------------------------------------------------------------
# Logging
# -------------------------------------------------------------------------------------------------
logger:
  print_freq: 100
  save_checkpoint_freq: 5000
  save_checkpoint_format: safetensors
  use_tb_logger: true
