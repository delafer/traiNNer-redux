name: 2xParagonSR2_S_DeJPEG_Ultimate
scale: 2
use_amp: true
amp_bf16: true
use_channels_last: true
fast_matmul: true
num_gpu: auto

datasets:
  train:
    name: Train_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/lr_x2_jpg
    lq_size: 128
    use_hflip: true
    use_rot: true
    num_worker_per_gpu: 8
    # S-Model is larger -> Lower Batch Size to fit VRAM with heavy losses
    batch_size_per_gpu: 4
    accum_iter: 2          # Accumulate to simulate batch size 8

  val:
    name: Val_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_x2_jpg

network_g:
  type: paragonsr2_static_s
  # Ensure hr_blocks matches your Pretrain (S usually has 2, Micro has 1)
  hr_blocks: 2

network_d:
  type: munet

path:
  # Point to your FINISHED 'S' Perceptual Model
  pretrain_network_g: experiments/2xParagonSR2_S_with_FeatureMatching_Optimized/models/net_g_latest.safetensors
  strict_load_g: true
  resume_state: ~

train:
  ema_decay: 0.995
  ema_power: 0.75
  grad_clip: true

  optim_g:
    type: AdamW
    lr: !!float 5e-5      # Fine-tune LR
    weight_decay: !!float 1.0e-4
    betas: [0.9, 0.99]

  optim_d:
    type: AdamW
    lr: !!float 5e-5
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [30000, 45000]
    gamma: 0.5

  total_iter: 50000
  warmup_iter: 200

  losses:
    # 1. Base Pixel Loss
    - type: charbonnierloss
      loss_weight: 1.0
      start_iter: 0
      target_iter: 50000
      target_weight: 0.5
      schedule_type: linear

    # 2. Perceptual (ConvNeXt)
    - type: convnextperceptualloss
      loss_weight: 0.5
      start_iter: 0
      layers: [1, 2]
      layer_weights: [1.0, 0.7]

    # 3. DISTS (The "S" Model Special)
    # Excellent for texture restoration. S-Model has capacity to learn this.
    - type: distsloss
      loss_weight: 0.05
      start_iter: 0

    # 4. Adaptive Block TV (The Anti-JPEG Special)
    - type: AdaptiveBlockTVLoss
      loss_weight: 0.05
      start_iter: 0
      block_size: 8 # Targets 8x8 JPEG blocks

    # 5. GAN (R3GAN)
    # R1/R2 at 0.0 for speed, but R3GAN logic kept for quality
    - type: ganloss
      gan_type: r3gan
      loss_weight: 0.05
      start_iter: 0
      r1_weight: 0.0
      r2_weight: 0.0

    # 6. Feature Matching
    - type: featurematchingloss
      loss_weight: 0.5
      start_iter: 0
      layers: [ 'down2', 'mid' ] # Drop down1 to save VRAM for S model
      criterion: charbonnier

    # 7. LDL (Anti-Artifact)
    - type: ldlloss
      loss_weight: 0.5
      start_iter: 0

      # Consistency Loss (Robustness)
    - type: ConsistencyLoss
      loss_weight: 0.05  # Keep weight low, it's a regularizer
      start_iter: 0

val:
  val_enabled: true
  val_freq: 5000
  save_img: true
  metrics_enabled: true
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 2

logger:
  print_freq: 20
  save_checkpoint_freq: 5000
  save_checkpoint_format: safetensors
  use_tb_logger: true
