# yaml-language-server: $schema=https://raw.githubusercontent.com/the-database/traiNNer-redux/refs/heads/master/schemas/redux-config.schema.json
# -------------------------------------------------------------------------------------------------
# ParagonSR2-STATIC-S (Microtexture Fix - Resume) - Enable High FFLoss Immediately
# Resume configuration for immediate ffloss activation to fix pixely appearance
#
# RESUME STRATEGY:
# Since using perceptual model as pretrain, enable high ffloss immediately with 0.40 weight.
# This addresses the extremely low ffloss values (3e-05) that are causing pixely textures.
#
# IMMEDIATE FFLOSS ACTIVATION:
# - Set start_iter: 0 for immediate activation
# - Increase initial weight: 0.40 (vs current 0.20)
# - Keep target weight: 0.55 (proven optimal)
# - Expected ffloss values: 1e-4 to 1e-3 range
#
# Author: Philip Hofmann
# Resume configuration for immediate ffloss fix
# -------------------------------------------------------------------------------------------------

name: 2xParagonSR2_S_microtexture_balanced_resume
scale: 2

# -------------------------------------------------------------------------------------------------
# PERFORMANCE OPTIMIZATION FLAGS
# -------------------------------------------------------------------------------------------------
use_amp: true                          # Enable Automatic Mixed Precision for faster training
amp_bf16: true                        # Use BF16 for better numerical stability on Ampere+ GPUs
use_channels_last: true               # Optimize memory layout for better performance
fast_matmul: true                     # Trade precision for speed in matrix operations
num_gpu: auto                        # Automatically detect and use available GPUs

# -------------------------------------------------------------------------------------------------
# DATASET CONFIGURATION
# -------------------------------------------------------------------------------------------------
datasets:
  train:
    name: Train_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/lr_x2
    lq_size: 128                      # Input patch size - balanced for memory vs. context
    use_hflip: true                   # Horizontal flips for data augmentation
    use_rot: true                     # Rotations for better spatial invariance
    num_worker_per_gpu: 8             # Parallel data loading
    batch_size_per_gpu: 8             # Batch size per GPU - tuned for 8GB VRAM
    accum_iter: 1                     # Gradient accumulation steps

  val:
    name: Val_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_x2

# -------------------------------------------------------------------------------------------------
# NETWORK ARCHITECTURE
# -------------------------------------------------------------------------------------------------
network_g:
  type: paragonsr2_static_s          # S-sized static ParagonSR2 for perceptual training

network_d:
  type: munet                        # MUNet discriminator for R3GAN

# -------------------------------------------------------------------------------------------------
# PRETRAINING & RESUME CONFIGURATION
# -------------------------------------------------------------------------------------------------
path:
  pretrain_network_g: experiments/2xParagonSR2_S_static_perceptual_r3_v1/models/net_g_ema_135000.safetensors # Perceptual model
  strict_load_g: true                # Load exact weights from perceptual model
  resume_state: ~                    # Fresh training from perceptual pretrain
# -------------------------------------------------------------------------------------------------
# TRAINING OPTIMIZATION SETTINGS
# -------------------------------------------------------------------------------------------------
train:
  ema_decay: 0.995                   # Exponential Moving Average decay for stable training
  ema_power: 0.75                   # EMA power for momentum calculation
  grad_clip: true                   # Enable gradient clipping for stability

  # Generator optimizer configuration
  optim_g:
    type: AdamW                      # AdamW for better weight decay handling
    lr: !!float 8.0e-5              # Slightly lower LR for careful fine-tuning
    weight_decay: !!float 1.0e-4     # L2 regularization
    betas: [0.9, 0.99]              # AdamW beta parameters

  # Discriminator optimizer configuration
  optim_d:
    type: AdamW
    lr: !!float 1.2e-4              # Adjusted for perceptual training
    weight_decay: !!float 0.0       # No weight decay on discriminator
    betas: [0.9, 0.99]

  # Learning rate scheduler
  scheduler:
    type: MultiStepLR
    milestones: [80000, 120000]      # Adjusted for remaining training
    gamma: 0.5                       # Reduce LR by 50% at each milestone

  total_iter: 140000                 # Total training iterations (140k) - same as original
  warmup_iter: 2000                  # Extended warmup for stability

  # -------------------------------------------------------------------------------------------------
  # RESUME WITH IMMEDIATE FFLOSS ACTIVATION
  # -------------------------------------------------------------------------------------------------
  #
  # RESUME PHILOSOPHY:
  # Resume training from 15k iterations with immediate high ffloss activation.
  # Since using perceptual pretrain, can afford aggressive ffloss enhancement.
  # Immediate activation should fix pixely appearance within next few thousand iterations.
  #
  # KEY CHANGES FOR RESUME:
  # - ffloss start_iter: 0 (immediate activation)
  # - ffloss initial weight: 0.40 (vs original 0.20)
  # - ffloss target weight: 0.55 (same proven target)
  # - All other losses: same as original for stability
  # -------------------------------------------------------------------------------------------------
  losses:

    # ===============================================================================================
    # 1) MODERATE PIXEL LOSS - SAME AS ORIGINAL
    # ===============================================================================================
    - type: charbonnierloss
      loss_weight: 0.7               # Moderate reduction for ffloss enhancement
      start_iter: 0                  # Active with moderate influence
      target_iter: 20000            # Gradual reduction over longer period
      target_weight: 0.5             # Still significant for structure preservation
      schedule_type: linear          # Gradual transition for stability

    # ===============================================================================================
    # 2) CONVNEXT PERCEPTUAL LOSS - SAME AS ORIGINAL
    # ===============================================================================================
    - type: convnextperceptualloss
      loss_weight: 0.14              # Slight increase to maintain perceptual quality
      layers: [1, 2]                 # Optimal perceptual layers
      layer_weights: [1.0, 0.7]      # Balanced layer weighting
      eps: 1.0e-6                   # Numerical stability
      start_iter: 0                  # Active from beginning for quality preservation
      target_iter: 30000            # Gradual ramp for stable enhancement
      target_weight: 0.28           # Strong but balanced enhancement

    # ===============================================================================================
    # 3) DISTS LOSS - SAME AS ORIGINAL
    # ===============================================================================================
    - type: distsloss
      loss_weight: 0.10              # Slight increase for better perceptual balance
      as_loss: true                  # Direct loss function
      load_weights: true            # Load pretrained weights
      use_input_norm: true          # Normalize inputs

    # ===============================================================================================
    # 4) IMMEDIATE HIGH FREQUENCY LOSS - RESUME FIX
    # ===============================================================================================
    #
    # PURPOSE: IMMEDIATE high ffloss activation to fix pixely appearance
    # RATIONALE: Set start_iter: 0 and increase initial weight to 0.40
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.40 → IMMEDIATE high weight (vs original 0.20)
    # - start_iter: 0 → IMMEDIATE activation (vs original 5000)
    # - target_iter: 95000 → Adjusted for resume (original 80000 + 15000 resume)
    # - target_weight: 0.55 → Same proven optimal target
    # - schedule_type: linear → Same gradual enhancement
    #
    # EXPECTED FFLOSS VALUES:
    # - With 0.40 initial weight, expect ffloss around 1e-4 to 1e-3
    # - This should be 5-10x higher than current problematic 3e-05
    # - Expected improvement: Pixely appearance should improve within 5k iterations
    #
    # WHY THIS MATTERS: Immediate high ffloss activation addresses the core issue
    #                  of extremely low ffloss values causing pixely textures.
    #                  The 0.40 weight should provide immediate microtexture
    #                  enhancement to fix the current degradation.
    # ===============================================================================================
    - type: ffloss
      loss_weight: 0.40              # IMMEDIATE high weight for instant effect
      start_iter: 0                  # IMMEDIATE activation - critical for fix
      target_iter: 95000            # Adjusted for resume duration
      target_weight: 0.55           # Same proven optimal target
      schedule_type: linear         # Same gradual enhancement

    # ===============================================================================================
    # 5) GRADIENT VARIANCE LOSS - SAME AS ORIGINAL
    # ===============================================================================================
    - type: GradientVarianceLoss
      loss_weight: 0.04              # Balanced weight for texture control
      start_iter: 1000               # Early activation for texture stability
      patch_size: 16                # Optimal patch size for detail analysis
      criterion: charbonnier        # Robust texture analysis

    # ===============================================================================================
    # 6) LDL LOSS - ADJUSTED FOR RESUME
    # ===============================================================================================
    - type: ldlloss
      loss_weight: 0.4               # Standard weight for artifact suppression
      disable_after: 95000          # Adjusted for resume training

    # ===============================================================================================
    # 7) R3GAN LOSS - ADJUSTED FOR RESUME
    # ===============================================================================================
    - type: ganloss
      gan_type: r3gan
      loss_weight: 0.00
      start_iter: 35000             # Adjusted for resume timing
      target_weight: 0.07           # Moderate adversarial enhancement
      r1_weight: 2.0               # Strong regularization
      r2_weight: 2.0               # Balanced training

    # ===============================================================================================
    # 8) CONTRASTIVE LOSS - ADJUSTED FOR RESUME
    # ===============================================================================================
    - type: ContrastiveLoss
      loss_weight: 0.00
      temperature: 0.1              # Sharp contrastive features
      start_iter: 55000             # Adjusted for resume timing
      target_weight: 0.04           # Standard weight for subtle enhancement

# -------------------------------------------------------------------------------------------------
# VALIDATION CONFIGURATION
# -------------------------------------------------------------------------------------------------
val:
  val_enabled: true                 # Enable validation during training
  val_freq: 5000                   # Validate every 5k iterations
  save_img: true                   # Save validation images for progress monitoring
  metrics_enabled: true            # Enable automatic metric calculation

  # Comprehensive metric suite for quality assessment
  metrics:
    psnr:                          # Peak Signal-to-Noise Ratio (fidelity metric)
      type: calculate_psnr
      crop_border: 2               # Standard crop for fair comparison

    ssim:                          # Structural Similarity Index (structural quality)
      type: calculate_ssim
      crop_border: 2

    lpips:                         # Learned Perceptual Image Patch Similarity (perceptual quality)
      type: calculate_lpips
      better: lower               # Lower LPIPS = better perceptual quality

    dists:                         # Deep Image Structure and Texture Similarity
      type: calculate_dists
      better: lower

    topiq:                         # Task-Oriented Perceptual Image Quality
      type: calculate_topiq

# -------------------------------------------------------------------------------------------------
# LOGGING CONFIGURATION
# -------------------------------------------------------------------------------------------------
logger:
  print_freq: 100                  # Print training progress every 100 iterations
  save_checkpoint_freq: 5000       # Save model checkpoints every 5k iterations
  save_checkpoint_format: safetensors # Use SafeTensors format for better compatibility
  use_tb_logger: true              # Enable TensorBoard logging for detailed monitoring

# -------------------------------------------------------------------------------------------------
# RESUME EXPECTATIONS & SUCCESS METRICS
# -------------------------------------------------------------------------------------------------
#
# IMMEDIATE EXPECTATIONS:
# - ffloss should jump to 1e-4 to 1e-3 range immediately
# - Pixely/dotted appearance should improve within 5k iterations
# - Training should remain stable with 0.40 weight
# - Gradual improvement should continue toward target 0.55
#
# RESUME SUCCESS INDICATORS:
# - ffloss contribution: Should be 5-10x higher than current 3e-05
# - Visual improvement: Pixely textures should become crisp
# - Stable training: No sudden instability from weight increase
# - Continued progression: Should reach 0.55 target by 95k iterations
#
# MONITORING CHECKPOINTS:
# - 20k: Verify immediate ffloss boost and visual improvement
# - 25k: Confirm pixely appearance is significantly reduced
# - 30k: Check for continued stable improvement
# - 40k: Assess overall quality vs original fidelity model
#
# RESUME INSTRUCTIONS:
# 1. Use the training state from 15k iterations as resume point
# 2. Monitor ffloss values - should jump to 1e-4 range immediately
# 3. Check visual quality - pixely textures should improve within 5k iterations
# 4. Ensure training stability with the higher ffloss weight
#
# This resume configuration should immediately fix the pixely appearance
# by providing high ffloss values while maintaining training stability.
# -------------------------------------------------------------------------------------------------
