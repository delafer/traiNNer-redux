# yaml-language-server: $schema=https://raw.githubusercontent.com/the-database/traiNNer-redux/refs/heads/master/schemas/redux-config.schema.json
#########################################################################################
# Optimized Static Pretrain Config for ParagonSR2 S
# Goals: Clean fidelity pretrain, artifact-free, fast, deployable
#########################################################################################
name: 2xParagonSR2_static_Micro_fidelity
scale: 2

use_amp: true           # Enable automatic mixed precision
amp_bf16: true          # Use bf16 instead of fp16 for supported GPUs
use_channels_last: true # Memory-friendly format for speed
fast_matmul: false      # Precision-over-speed tradeoff
num_gpu: auto           # Automatically detect available GPUs
manual_seed: 1024       # Optional: fixes randomness for reproducibility

#########################################################################################
# Dataset & Dataloader Settings
#########################################################################################
datasets:
  train:
    name: Train Dataset
    type: pairedimagedataset
    dataroot_gt: [/home/phips/Documents/dataset/cc0/hr]
    dataroot_lq: [/home/phips/Documents/dataset/cc0/lr_x2]
    lq_size: 128
    use_hflip: true
    use_rot: true
    num_worker_per_gpu: 8
    batch_size_per_gpu: 8
    accum_iter: 1

  val:
    name: Val Dataset
    type: pairedimagedataset
    dataroot_gt: [/home/phips/Documents/dataset/cc0/val_hr]
    dataroot_lq: [/home/phips/Documents/dataset/cc0/val_lr_x2]

#########################################################################################
# Generator Network
#########################################################################################
network_g:
  type: paragonsr2_static_micro
  # Static pretrain: no dynamic kernels, fully compatible with ONNX conversion

#########################################################################################
# Pretrain & Resume Paths
#########################################################################################
path:
  param_key_g: ~
  strict_load_g: true   # Ensures weights are loaded only if names match exactly
  resume_state: ~

#########################################################################################
# Training Settings
#########################################################################################
train:
  ema_decay: 0.999
  ema_power: 0.75
  grad_clip: true

  # Optimizer for Generator
  optim_g:
    type: AdamW
    lr: !!float 1e-4          # Slightly lower for stability
    weight_decay: !!float 1e-4        # Mild regularization
    betas: [0.9, 0.99]

  # Scheduler: MultiStepLR for stable decay
  scheduler:
    type: MultiStepLR
    milestones: [200000, 300000, 350000]
    gamma: 0.5

  total_iter: 400000
  warmup_iter: 1000  # Gradually ramp up LR for stable early training

  # Loss stack: minimal fidelity-focused
  losses:
    # 1) Charbonnier Loss: smooth gradient, robust to noise
    - type: charbonnierloss
      loss_weight: 1.0

#########################################################################################
# Validation Settings
#########################################################################################
val:
  val_enabled: true
  val_freq: 5000
  save_img: true
  tile_size: 0
  tile_overlap: 8

  metrics_enabled: true
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 4
      test_y_channel: false
    ssim:
      type: calculate_ssim
      crop_border: 4
      test_y_channel: false
    # Optional perceptual metrics for monitoring
    #lpips:
    #  type: calculate_lpips
    #  better: lower
    #dists:
    #  type: calculate_dists
    #  better: lower
    #topiq:
    #  type: calculate_topiq

#########################################################################################
# Logging
#########################################################################################
logger:
  print_freq: 100
  save_checkpoint_freq: 5000
  save_checkpoint_format: safetensors
  use_tb_logger: true
