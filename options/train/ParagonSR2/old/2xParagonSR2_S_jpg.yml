name: 2xParagonSR2_S_DeJPEG_Hybrid
scale: 2
use_amp: true
amp_bf16: true
use_channels_last: true
fast_matmul: true
num_gpu: auto

datasets:
  train:
    name: Train_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/lr_x2_jpg
    lq_size: 128
    use_hflip: true
    use_rot: true
    num_worker_per_gpu: 8
    batch_size_per_gpu: 4
    accum_iter: 1

  val:
    name: Val_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_x2_jpg

network_g:
  type: paragonsr2_s
  scale: 2
  # ParagonSR2 Hybrid uses sensible defaults from factory function
  # upsampler_alpha: 0.5  # MagicKernel sharpening (default)
  # detail_gain: 0.1      # Initial detail contribution (default)
  # fast_body_mode: true  # Enabled by default for training speed

network_d:
  type: munet

path:
  # TODO: Update this path to your pretrained hybrid model when available
  # pretrain_network_g: experiments/2xParagonSR2_S_Hybrid_Pretrain/models/net_g_ema_XXXXX.safetensors
  pretrain_network_g: ~
  strict_load_g: true
  resume_state: ~

train:
  ema_decay: 0.995
  ema_power: 0.75
  grad_clip: true

  optim_g:
    type: AdamW
    lr: !!float 1e-4
    weight_decay: !!float 1.0e-4
    betas: [0.9, 0.99]

  optim_d:
    type: AdamW
    lr: !!float 3e-5 # Start conservative to prevent discriminator domination
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [30000, 45000]
    gamma: 0.5

  total_iter: 50000
  warmup_iter: 200

  # =========================================================================
  # OPTIMIZED LOSS STACK FOR JPEG DE-ARTIFACTING (Hybrid Architecture)
  # =========================================================================

  # Charbonnier → Pixel accuracy
  # Perceptual → Structure
  # DISTS → Texture quality
  # Feature Matching → Discriminator alignment
  # LDL → Local artifact removal
  # Consistency → Color stability
  # FF → Frequency domain
  # AdaptiveBlockTV → JPEG block artifacts
  # GAN → Photorealism

  losses:
    # 1. PIXEL LOSS: Stable foundation
    - type: charbonnierloss
      loss_weight: 0.8
      start_iter: 0
      target_iter: 25000
      target_weight: 0.1
      schedule_type: linear

    # 2. PERCEPTUAL: Core structural loss
    - type: convnextperceptualloss
      loss_weight: 0.5
      start_iter: 0
      layers: [1, 2]
      layer_weights: [1.0, 0.7]

    # 3. DISTS: Texture quality
    - type: distsloss
      loss_weight: 0.1
      start_iter: 0

    # 4. FEATURE MATCHING: Discriminator guidance
    - type: featurematchingloss
      loss_weight: 0.5
      start_iter: 0
      layers: ["down2", "mid"] # Keep 2 layers for efficiency
      criterion: charbonnier

    # 5. LDL: Anti-JPEG artifact loss
    - type: ldlloss
      loss_weight: 10.0
      start_iter: 0

    # 6. CONSISTENCY: Color stability
    - type: ConsistencyLoss
      loss_weight: 0.25
      start_iter: 0
      criterion: "chc"
      blur: false
      brightness: 1.0
      saturation: 1.0
      cosim: true
      cosim_weight: 0.5

    # 7. FF LOSS: Frequency domain
    - type: ffloss
      loss_weight: 0.1
      start_iter: 5000
      target_iter: 25000
      target_weight: 0.2
      schedule_type: linear

    # 8. ADAPTIVE BLOCK TV: JPEG block targeting
    - type: AdaptiveBlockTVLoss
      loss_weight: 0.005 # Low weight
      start_iter: 0
      block_size: 8 # Target JPEG blocks
      sharpness: 4.0
      reduction: mean
      eps: 1e-6

    # 9. GAN: Texture generation
    - type: ganloss
      gan_type: r3gan
      loss_weight: 0.0001
      start_iter: 10000
      target_iter: 25000
      target_weight: 0.03 # Conservative (not 0.1)
      r1_weight: 1.0 # Used for stability
      r2_weight: 0.0 # DISABLED for speed and vram saving
      schedule_type: linear

val:
  val_enabled: true
  val_freq: 2500
  save_img: true
  metrics_enabled: true
  metrics:
    # PSNR - Peak Signal-to-Noise Ratio (pixel-wise reconstruction fidelity)
    psnr:
      type: calculate_psnr
      crop_border: 2 # Ignore 2-pixel border (avoids boundary artifacts)

    # SSIM - Structural Similarity Index (structural preservation)
    ssim:
      type: calculate_ssim
      crop_border: 2 # Consistent crop for fair comparison

    # LPIPS - Learned Perceptual Image Patch Similarity (perceptual quality)
    lpips:
      type: calculate_lpips
      better: lower # Lower LPIPS = better perceptual quality

    # DISTS - Deep Image Structure and Texture Similarity (texture quality)
    dists:
      type: calculate_dists
      better: lower # Lower DISTS = better structure/texture match

    # ToPIQ - Transferable Perceptual Image Quality (comprehensive quality)
    topiq:
      type: calculate_topiq

logger:
  print_freq: 50
  save_checkpoint_freq: 2500
  save_checkpoint_format: safetensors
  use_tb_logger: true
