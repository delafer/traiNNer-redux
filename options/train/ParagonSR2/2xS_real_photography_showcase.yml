# yaml-language-server: $schema=https://raw.githubusercontent.com/the-database/traiNNer-redux/refs/heads/master/schemas/redux-config.schema.json
#########################################################################################
# ParagonSR2 S - Real World Photography SHOWCASE MODEL
#########################################################################################
# This config demonstrates ALL ParagonSR innovations for the SISR community:
# - MuNet discriminator (custom implementation) with R3GAN regularization
# - Advanced loss stack: ConvNeXt, ConsistencyLoss, FeatureMatching, AdaptiveBlockTV
# - Paragon OTF degradation sequences (modern compression + video artifacts)
# - Loss scheduling for progressive training
# - State-of-the-art techniques not standard in SISR yet
#
# Training: Load from 2xS_perceptual (perceptual base) â†’ Add GAN + OTF
# Expected time: ~4 hours on RTX 3060 (12GB VRAM, batch_size 6)
# Deployment: ~30 FPS @ 1080p with TensorRT FP16
#########################################################################################

name: 2xParagonSR2_S_RealPhoto_Showcase
scale: 2

use_amp: true
amp_bf16: true
use_channels_last: true
fast_matmul: false
num_gpu: auto

# ========================================================================
# OTF DEGRADATION SETTINGS
# Enable on-the-fly degradation with physically accurate ordering
# ========================================================================
high_order_degradation: true

# Blur kernel probabilities (for defocus blur stage)
blur_prob: 0.3

# Final resize mode (quality-focused for ISP stage)
resize_mode_list3: [bicubic, bilinear]
resize_mode_prob3: [0.7, 0.3]

# === REALISTIC COMPRESSION PIPELINE ===
# Replaces old sequential WebP/AVIF/HEIF compression with unified approach
# Each compression round chooses ONE format (mutually exclusive)

# Initial compression (camera/editor saves file) - always applied
compression_formats: [jpeg, webp, avif, heif]
compression_weights: [0.60, 0.25, 0.10, 0.05] # JPEG most common
compression_jpeg_range: [45, 95]
compression_webp_range: [60, 85]
compression_avif_range: [65, 90]
compression_heif_range: [70, 90]

# Platform recompression (upload service processes image) - optional
recompression_prob: 0.5
recompression_formats: [jpeg, webp, avif, heif]
recompression_weights: [0.50, 0.35, 0.10, 0.05]

# === CAMERA ARTIFACTS (Realistic for Internet Photography) ===
sensor_noise_prob: 0.5
sensor_noise_std_range: [0.015, 0.06] # ISO 100-1600 range
motion_blur_prob: 0.2
motion_blur_kernel_size: [3, 9]
motion_blur_angle_range: [0, 360]
lens_distort_prob: 0.25
lens_distort_strength_range: [-0.1, 0.2]
rolling_shutter_prob: 0.15
rolling_shutter_strength_range: [0.01, 0.06]
chromatic_aberration_prob: 0.4

# === PHOTO PROCESSING & EDITING ===
oversharpen_prob: 0.4
oversharpen_strength: [1.1, 1.5]
exposure_prob: 0.3
exposure_factor_range: [0.90, 1.15]
color_temp_prob: 0.35
color_temp_shift_range: [-0.15, 0.15]
aliasing_prob: 0.2
aliasing_scale_range: [0.6, 0.9]
demosaic_prob: 0.1

# === OPTIONAL EDITING STAGE ===
# Simulates social media filters and photo editing apps
editing_prob: 0.4
editing_exposure_prob: 0.6
editing_exposure_range: [0.95, 1.10]
editing_oversharpen_prob: 0.4
editing_oversharpen_strength: [1.05, 1.3]

queue_size: 120

datasets:
  train:
    name: Train
    type: realesrgandataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/hr
    gt_size: 256
    use_hflip: false
    use_rot: false

    # Blur kernel generation (stays in dataset section)
    blur_kernel_size: 21
    kernel_list:
      [
        "iso",
        "aniso",
        "generalized_iso",
        "generalized_aniso",
        "plateau_iso",
        "plateau_aniso",
      ]
    kernel_prob: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
    sinc_prob: 0.1
    blur_sigma: [0.2, 3.0]
    betag_range: [0.5, 4.0]
    betap_range: [1, 2]

    # Second kernel for variety (stays in dataset section)
    blur_kernel_size2: 21
    kernel_list2:
      [
        "iso",
        "aniso",
        "generalized_iso",
        "generalized_aniso",
        "plateau_iso",
        "plateau_aniso",
      ]
    kernel_prob2: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
    sinc_prob2: 0.1
    blur_sigma2: [0.2, 1.5]
    betag_range2: [0.5, 4.0]
    betap_range2: [1, 2]

    # Final sinc kernel
    final_sinc_prob: 0.1
    final_kernel_range: [7, 21]

    num_worker_per_gpu: 6
    batch_size_per_gpu: 6
    accum_iter: 1

  val:
    name: Val
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_realistic # Pre-degraded with OTF

network_g:
  type: paragonsr2_s

network_d:
  type: munet # Custom MuNet discriminator

path:
  # Load perceptual pretrain for strong initialization
  pretrain_network_g: experiments/2xParagonSR2_S_Perceptual/models/net_g_ema_60000.safetensors
  strict_load_g: true
  resume_state: ~

train:
  ema_decay: 0.999
  ema_power: 0.75
  grad_clip: true

  # Generator optimizer
  optim_g:
    type: AdamW
    lr: !!float 5e-5 # Lower LR for GAN stability
    weight_decay: !!float 1e-4
    betas: [0.9, 0.99]

  # Discriminator optimizer
  optim_d:
    type: AdamW
    lr: !!float 5e-5
    weight_decay: 0
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [20000, 35000, 50000]
    gamma: 0.5

  total_iter: 60000
  warmup_iter: 200

  # ========================================================================
  # ADVANCED LOSS STACK - ParagonSR Showcase
  # Demonstrates all custom implementations + loss scheduling
  # ========================================================================

  losses:
    # === ACTIVE LOSSES (Core Stack) ===

    # Pixel-level fidelity (ramping down for perceptual dominance)
    - type: charbonnierloss
      loss_weight: 1.0
      target_iter: 30000
      target_weight: 0.08 # Low for photorealism
      schedule_type: linear

    # ConvNeXt perceptual (CUSTOM IMPLEMENTATION - better than VGG)
    - type: convnextperceptualloss
      loss_weight: 0.2 # Main perceptual driver
      layers: [1, 2]
      layer_weights: [1.0, 0.7]

    # DISTS texture quality
    - type: distsloss
      loss_weight: 0.15

    # ConsistencyLoss (CUSTOM - color stability)
    - type: ConsistencyLoss
      loss_weight: 0.12
      criterion: "chc"
      blur: false
      cosim: true
      cosim_weight: 0.5

    # LDL (local distribution learning)
    - type: ldlloss
      loss_weight: 0.8
      loss_decay: 0.8
      loss_decay_inflection: 35000

    # High-frequency edge detail
    - type: hfenloss
      loss_weight: 0.08
      start_iter: 2000
      kernel_size: 7
      sigma: 1.0
      criterion: charbonnier

    # Laplacian edge preservation
    - type: laplacianpyramidloss
      loss_weight: 0.25
      start_iter: 2500
      criterion: charbonnier

    # AdaptiveBlockTV (CUSTOM - intelligent structure preservation)
    - type: AdaptiveBlockTVLoss
      loss_weight: 0.01
      block_size: 8
      sharpness: 4.0

    # Feature Matching (CUSTOM - leverages MuNet discriminator features)
    - type: FeatureMatchingLoss
      loss_weight: 0.15
      start_iter: 10000 # Start with GAN
      criterion: charbonnier
      # Uses all MuNet discriminator features automatically

    # GAN loss (R3GAN integrated)
    - type: r3ganloss
      loss_weight: 0.08
      start_iter: 10000 # Start GAN after perceptual stabilizes
      r1_weight: 10.0 # R1 gradient penalty weight
      r2_weight: 10.0 # R2 gradient penalty weight

    # === COMMENTED LOSSES (For Community Documentation) ===
    # These are NOT active but included to showcase the full toolkit

    # ContrastiveLoss - Not needed (ConvNeXt perceptual already covers)
    # - type: contrastiveloss
    #   loss_weight: 0  # DISABLED: Redundant with ConvNeXt
    #   temperature: 0.07

    # GradientVarianceLoss - Not needed (HFEN covers high-frequency)
    # - type: gradientvarianceloss
    #   loss_weight: 0  # DISABLED: Overlaps with HFEN
    #   criterion: charbonnier

    # FFLoss - Not needed (AdaptiveBlockTV is more intelligent)
    # - type: ffloss
    #   loss_weight: 0  # DISABLED: AdaptiveBlockTV is superior
    #   loss_decay: 0.5

  # Mix of Augmentations (advanced data augmentation)
  use_moa: false # OTF degradations provide sufficient diversity

val:
  val_enabled: true
  val_freq: 2000
  save_img: true

  metrics_enabled: true
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 2
    ssim:
      type: calculate_ssim
      crop_border: 2
    lpips:
      type: calculate_lpips
      better: lower
    dists:
      type: calculate_dists
      better: lower
    topiq:
      type: calculate_topiq

logger:
  print_freq: 50
  save_checkpoint_freq: 2000
  save_checkpoint_format: safetensors
  use_tb_logger: true

  # OTF degradation debugging (optional)
  high_order_degradations_debug: false # Set true to save degraded samples
  high_order_degradations_debug_limit: 100
