# yaml-language-server: $schema=https://raw.githubusercontent.com/the-database/traiNNer-redux/refs/heads/master/schemas/redux-config.schema.json
# -------------------------------------------------------------------------------------------------
# ParagonSR2-STATIC-S (Microtexture Fix - Balanced) - Fix Grid Pattern Conservative
# Uses current trained perceptual model with moderate ffloss enhancement
#
# BALANCED APPROACH RATIONALE:
# This config addresses the artificial grid pattern while preserving the good perceptual
# qualities of the already-trained model. Uses moderate ffloss enhancement to fix
# microtexture issues without overwriting beneficial features.
#
# BALANCED STRATEGY:
# - Moderate ffloss enhancement (0.20→0.55) - aggressive but not extreme
# - Preserve perceptual quality by maintaining strong perceptual losses
# - Gradual ffloss ramp over longer period for stable integration
# - Keep good features while enhancing microtexture details
#
# Author: Philip Hofmann
# Based on balanced approach to preserve good features while fixing ffloss
# -------------------------------------------------------------------------------------------------

name: 2xParagonSR2_S_microtexture_balanced
scale: 2

# -------------------------------------------------------------------------------------------------
# PERFORMANCE OPTIMIZATION FLAGS
# -------------------------------------------------------------------------------------------------
use_amp: true                          # Enable Automatic Mixed Precision for faster training
amp_bf16: true                        # Use BF16 for better numerical stability on Ampere+ GPUs
use_channels_last: true               # Optimize memory layout for better performance
fast_matmul: true                     # Trade precision for speed in matrix operations
num_gpu: auto                        # Automatically detect and use available GPUs

# -------------------------------------------------------------------------------------------------
# DATASET CONFIGURATION
# -------------------------------------------------------------------------------------------------
datasets:
  train:
    name: Train_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/lr_x2
    lq_size: 128                      # Input patch size - balanced for memory vs. context
    use_hflip: true                   # Horizontal flips for data augmentation
    use_rot: true                     # Rotations for better spatial invariance
    num_worker_per_gpu: 8             # Parallel data loading
    batch_size_per_gpu: 8             # Batch size per GPU - tuned for 8GB VRAM
    accum_iter: 1                     # Gradient accumulation steps

  val:
    name: Val_Dataset
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_x2

# -------------------------------------------------------------------------------------------------
# NETWORK ARCHITECTURE
# -------------------------------------------------------------------------------------------------
network_g:
  type: paragonsr2_static_s          # S-sized static ParagonSR2 for perceptual training

network_d:
  type: munet                        # MUNet discriminator for R3GAN

# -------------------------------------------------------------------------------------------------
# PRETRAINING & RESUME CONFIGURATION
# -------------------------------------------------------------------------------------------------
path:
  pretrain_network_g: experiments/2xParagonSR2_S_static_perceptual_r3_v1/models/net_g_ema_135000.safetensors
  strict_load_g: true                # Load exact weights from perceptual model
  resume_state: ~                    # Fresh training from perceptual pretrain

# -------------------------------------------------------------------------------------------------
# TRAINING OPTIMIZATION SETTINGS
# -------------------------------------------------------------------------------------------------
train:
  ema_decay: 0.995                   # Exponential Moving Average decay for stable training
  ema_power: 0.75                   # EMA power for momentum calculation
  grad_clip: true                   # Enable gradient clipping for stability

  # Generator optimizer configuration
  optim_g:
    type: AdamW                      # AdamW for better weight decay handling
    lr: !!float 8.0e-5              # Slightly lower LR for careful fine-tuning
    weight_decay: !!float 1.0e-4     # L2 regularization
    betas: [0.9, 0.99]              # AdamW beta parameters

  # Discriminator optimizer configuration
  optim_d:
    type: AdamW
    lr: !!float 1.2e-4              # Adjusted for perceptual training
    weight_decay: !!float 0.0       # No weight decay on discriminator
    betas: [0.9, 0.99]

  # Learning rate scheduler
  scheduler:
    type: MultiStepLR
    milestones: [80000, 120000]      # Conservative milestones for 140k training
    gamma: 0.5                       # Reduce LR by 50% at each milestone

  total_iter: 140000                 # Total training iterations (140k) - longer for gradual improvement
  warmup_iter: 2000                  # Extended warmup for stability

  # -------------------------------------------------------------------------------------------------
  # BALANCED LOSS SCHEDULING: 4-PHASE GRADUAL MICROTEXTURE ENHANCEMENT
  # -------------------------------------------------------------------------------------------------
  #
  # BALANCED PHILOSOPHY:
  # Gradually enhance microtexture while preserving existing perceptual quality.
  # Use moderate ffloss enhancement to fix grid issues without overwriting good features.
  # Longer training schedule allows stable integration of microtexture improvements.
  #
  # EXPECTED VISUAL PROGRESSION:
  # Phase 1 (0-20k):   Gradual ffloss introduction, maintain perceptual quality
  # Phase 2 (20k-60k): Moderate ffloss ramp with preserved perceptual features
  # Phase 3 (60k-100k): Fine-tuning balance between texture and perceptual quality
  # Phase 4 (100k+):    Final polish with maintained microtexture enhancement
  #
  # CONSERVATIVE FFLOSS APPROACH:
  # - Start with 0.20 weight (moderate, not extreme)
  # - Target 0.55 weight (aggressive but balanced)
  # - Gradual 80k ramp for stable integration
  # - Expected ffloss range: 5e-4 to 2e-3 (5-10x improvement over 3e-5)
  # -------------------------------------------------------------------------------------------------
  losses:

    # ===============================================================================================
    # 1) MODERATE PIXEL LOSS - PRESERVE STRUCTURE (GRADUAL REDUCTION)
    # ===============================================================================================
    #
    # PURPOSE: Moderate structural anchor while allowing ffloss to enhance microtexture
    # RATIONALE: Preserve structural quality while enabling microtexture improvement
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.7 → Moderate reduction to allow ffloss enhancement
    # - start_iter: 0 → Active with moderate influence
    # - target_iter: 20000 → Gradual reduction over longer period
    # - target_weight: 0.5 → Still significant for structure preservation
    # - schedule_type: linear → Gradual transition for stability
    #
    # WHY THIS MATTERS: Moderate pixel loss preserves structural quality while allowing
    #                  ffloss to enhance microtexture details. Balances improvement with stability.
    # ===============================================================================================
    - type: charbonnierloss
      loss_weight: 0.7               # Moderate reduction for ffloss enhancement
      start_iter: 0                  # Active with moderate influence
      target_iter: 20000            # Gradual reduction over longer period
      target_weight: 0.5             # Still significant for structure preservation
      schedule_type: linear          # Gradual transition for stability

    # ===============================================================================================
    # 2) MAINTAINED CONVNEXT PERCEPTUAL LOSS - PRESERVE QUALITY (GRADUAL RAMP)
    # ===============================================================================================
    #
    # PURPOSE: Maintain and slightly enhance perceptual quality while adding microtexture
    # RATIONALE: Preserve good perceptual features while allowing ffloss enhancement
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.14 → Slight increase to maintain perceptual dominance
    # - start_iter: 0 → Active from beginning for quality preservation
    # - target_iter: 30000 → Gradual ramp for stable enhancement
    # - target_weight: 0.28 → Strong but balanced enhancement
    # - layers: [1, 2] → Maintain optimal layer selection
    #
    # WHY THIS MATTERS: Slightly increased perceptual loss helps maintain and enhance
    #                  the good perceptual qualities while ffloss adds microtexture details.
    # ===============================================================================================
    - type: convnextperceptualloss
      loss_weight: 0.14              # Slight increase to maintain perceptual quality
      layers: [1, 2]                 # Optimal perceptual layers
      layer_weights: [1.0, 0.7]      # Balanced layer weighting
      eps: 1.0e-6                   # Numerical stability
      start_iter: 0                  # Active from beginning for quality preservation
      target_iter: 30000            # Gradual ramp for stable enhancement
      target_weight: 0.28           # Strong but balanced enhancement

    # ===============================================================================================
    # 3) MAINTAINED DISTS LOSS - CONSISTENT PERCEPTUAL BASE (FULL DURATION)
    # ===============================================================================================
    #
    # PURPOSE: Consistent perceptual enhancement throughout training
    # RATIONALE: Maintain stable perceptual foundation with slight increase
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.10 → Slight increase for better perceptual balance
    # - Active throughout training for consistent enhancement
    # - as_loss: true → Direct loss function usage
    # - load_weights: true → Load pretrained weights
    # - use_input_norm: true → Normalize inputs
    #
    # WHY THIS MATTERS: Consistent perceptual enhancement complements moderate ffloss
    #                  for comprehensive quality while preserving existing good features.
    # ===============================================================================================
    - type: distsloss
      loss_weight: 0.10              # Slight increase for better perceptual balance
      as_loss: true                  # Direct loss function
      load_weights: true            # Load pretrained weights
      use_input_norm: true          # Normalize inputs

    # ===============================================================================================
    # 4) MODERATE FREQUENCY LOSS - BALANCED MICROTEXTURE ENHANCEMENT (GRADUAL RAMP)
    # ===============================================================================================
    #
    # PURPOSE: Enhance microtexture to eliminate grid patterns while preserving perceptual quality
    # RATIONALE: MODERATE ffloss enhancement to fix issues without overwriting good features.
    #           This balances microtexture improvement with feature preservation.
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.20 → MODERATE initial weight (not extreme)
    # - start_iter: 5000 → Gradual start after warmup for stability
    # - target_iter: 80000 → Very gradual ramp over 75k iterations
    # - target_weight: 0.55 → AGGRESSIVE but BALANCED target weight
    # - schedule_type: linear → Very gradual enhancement
    #
    # EXPECTED FFLOSS VALUES:
    # - With 0.20 initial weight, expect ffloss around 5e-4 to 1e-3
    # - With 0.55 target weight, expect ffloss around 1e-3 to 2e-3
    # - These values should be 5-10x higher than problematic 3e-5
    #
    # WHY THIS MATTERS: This is a BALANCED approach. The moderate weights should provide
    #                  sufficient microtexture enhancement to eliminate grid patterns
    #                  without overwriting the good perceptual qualities already learned.
    #                  The gradual 75k ramp ensures stable integration of improvements.
    # ===============================================================================================
    - type: ffloss
      loss_weight: 0.20              # MODERATE initial weight (not extreme)
      start_iter: 5000               # Gradual start after warmup for stability
      target_iter: 80000            # Very gradual ramp over 75k iterations
      target_weight: 0.55           # AGGRESSIVE but BALANCED target weight
      schedule_type: linear         # Very gradual enhancement

    # ===============================================================================================
    # 5) GRADIENT VARIANCE LOSS - STABLE TEXTURE CONTROL (EARLY ACTIVATION)
    # ===============================================================================================
    #
    # PURPOSE: Prevent over-sharpening while allowing moderate ffloss enhancement
    # RATIONALE: Maintain texture regularity with balanced weight
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.04 → Balanced weight for texture control
    # - start_iter: 1000 → Early activation for texture stability
    # - patch_size: 16 → Maintain optimal patch size
    # - criterion: charbonnier → Robust texture analysis
    #
    # WHY THIS MATTERS: Balanced gradient variance loss prevents artifacts while
    #                  allowing the moderate ffloss enhancement to work effectively.
    # ===============================================================================================
    - type: GradientVarianceLoss
      loss_weight: 0.04              # Balanced weight for texture control
      start_iter: 1000               # Early activation for texture stability
      patch_size: 16                # Optimal patch size for detail analysis
      criterion: charbonnier        # Robust texture analysis

    # ===============================================================================================
    # 6) LDL LOSS - ARTIFACT SUPPRESSION (EXTENDED DURATION)
    # ===============================================================================================
    #
    # PURPOSE: Suppress artifacts during gradual training
    # RATIONALE: Extended duration for the longer training schedule
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.4 → Standard weight for artifact suppression
    # - disable_after: 80000 → Extended for gradual training duration
    #
    # WHY THIS MATTERS: Extended LDL coverage ensures artifact suppression throughout
    #                  the longer gradual training process.
    # ===============================================================================================
    - type: ldlloss
      loss_weight: 0.4               # Standard weight for artifact suppression
      disable_after: 80000          # Extended for gradual training

    # ===============================================================================================
    # 7) R3GAN LOSS - MODERATE ADVERSARIAL (STANDARD TIMING)
    # ===============================================================================================
    #
    # PURPOSE: Moderate adversarial enhancement after perceptual foundation
    # RATIONALE: Standard timing and weight for balanced adversarial training
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.00 → Base weight
    # - start_iter: 20000 → Standard timing after perceptual foundation
    # - target_weight: 0.07 → Moderate adversarial enhancement
    # - gan_type: r3gan → Maintain R3GAN for stability
    # - r1_weight: 2.0 → Strong regularization
    # - r2_weight: 2.0 → Balanced training
    #
    # WHY THIS MATTERS: Standard adversarial timing and weight for balanced enhancement
    #                  without interfering with the gradual ffloss ramp.
    # ===============================================================================================
    - type: ganloss
      gan_type: r3gan
      loss_weight: 0.00
      start_iter: 20000             # Standard timing after perceptual foundation
      target_weight: 0.07           # Moderate adversarial enhancement
      r1_weight: 2.0               # Strong regularization
      r2_weight: 2.0               # Balanced training

    # ===============================================================================================
    # 8) CONTRASTIVE LOSS - SEMANTIC ENHANCEMENT (STANDARD TIMING)
    # ===============================================================================================
    #
    # PURPOSE: Standard semantic enhancement after main training phases
    # RATIONALE: Standard timing for balanced contrastive learning
    #
    # SCHEDULE DECISION:
    # - loss_weight: 0.00 → Base weight
    # - start_iter: 40000 → Standard timing for contrastive enhancement
    # - target_weight: 0.04 → Standard weight for subtle enhancement
    # - temperature: 0.1 → Sharp contrastive features
    #
    # WHY THIS MATTERS: Standard contrastive timing and weight for balanced enhancement
    #                  without interfering with earlier training phases.
    # ===============================================================================================
    - type: ContrastiveLoss
      loss_weight: 0.00
      temperature: 0.1              # Sharp contrastive features
      start_iter: 40000             # Standard timing for contrastive enhancement
      target_weight: 0.04           # Standard weight for subtle enhancement

# -------------------------------------------------------------------------------------------------
# VALIDATION CONFIGURATION
# -------------------------------------------------------------------------------------------------
val:
  val_enabled: true                 # Enable validation during training
  val_freq: 5000                   # Validate every 5k iterations
  save_img: true                   # Save validation images for progress monitoring
  metrics_enabled: true            # Enable automatic metric calculation

  # Comprehensive metric suite for quality assessment
  metrics:
    psnr:                          # Peak Signal-to-Noise Ratio (fidelity metric)
      type: calculate_psnr
      crop_border: 2               # Standard crop for fair comparison

    ssim:                          # Structural Similarity Index (structural quality)
      type: calculate_ssim
      crop_border: 2

    lpips:                         # Learned Perceptual Image Patch Similarity (perceptual quality)
      type: calculate_lpips
      better: lower               # Lower LPIPS = better perceptual quality

    dists:                         # Deep Image Structure and Texture Similarity
      type: calculate_dists
      better: lower

    topiq:                         # Task-Oriented Perceptual Image Quality
      type: calculate_topiq

# -------------------------------------------------------------------------------------------------
# LOGGING CONFIGURATION
# -------------------------------------------------------------------------------------------------
logger:
  print_freq: 100                  # Print training progress every 100 iterations
  save_checkpoint_freq: 5000       # Save model checkpoints every 5k iterations
  save_checkpoint_format: safetensors # Use SafeTensors format for better compatibility
  use_tb_logger: true              # Enable TensorBoard logging for detailed monitoring

# -------------------------------------------------------------------------------------------------
# BALANCED SUCCESS METRICS & EXPECTATIONS
# -------------------------------------------------------------------------------------------------
#
# BALANCED SUCCESS INDICATORS:
# - ffloss range: 5e-4 to 2e-3 (5-10x improvement over 3e-5, not extreme)
# - Preserved perceptual quality: LPIPS should maintain or improve
# - Grid elimination: Artificial grid should disappear on detailed surfaces
# - Feature preservation: Good qualities from original model should be maintained
#
# EXPECTED VISUAL PROGRESSION:
# - 10k iterations: Beginning microtexture enhancement visible
# - 40k iterations: Moderate improvement in texture details
# - 80k iterations: Significant grid reduction with preserved quality
# - 120k iterations: Mature model with enhanced microtexture and maintained perceptual quality
#
# KEY MONITORING METRICS:
# - ffloss contribution: Should be moderate but significant (not dominant)
# - Visual inspection: Grid should gradually disappear while maintaining quality
# - Perceptual metrics: Should maintain or improve (not decrease)
# - Overall balance: Enhanced microtexture without losing good features
#
# QUALITY CHECKPOINTS:
# - 20k: Verify ffloss ramp is gradual and stable
# - 50k: Check microtexture improvement without quality loss
# - 80k: Confirm grid elimination with preserved perceptual quality
# - 120k: Final balanced assessment
#
# BALANCED APPROACH BENEFITS:
# - Fixes ffloss deficiency without extreme measures
# - Preserves good perceptual qualities from original model
# - Gradual improvement over longer training period
# - Lower risk of overwriting beneficial features
#
# This balanced configuration provides moderate ffloss enhancement to fix the grid
# pattern issue while preserving the good perceptual qualities you've already achieved.
# -------------------------------------------------------------------------------------------------
