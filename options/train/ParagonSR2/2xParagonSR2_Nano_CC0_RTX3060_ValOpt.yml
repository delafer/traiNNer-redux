# yaml-language-server: $schema=https://raw.githubusercontent.com/the-database/traiNNer-redux/refs/heads/master/schemas/redux-config.schema.json
#########################################################################################
# ParagonSR2 Nano - RTX 3060 VALIDATION-OPTIMIZED (Fixes OOM)
# This config fixes validation OOM by reducing validation batch size and memory usage
# Key fix: Smaller validation images + single-image validation to prevent attention OOM
#########################################################################################
name: 2xParagonSR2_Nano_CC0_RTX3060_ValOpt
scale: 2

use_amp: true
amp_bf16: false
use_channels_last: true
fast_matmul: true
num_gpu: auto
manual_seed: 1024

datasets:
  train:
    name: CC0_147k_Train_MemOpt
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/lr_x2_bicubic_aa
    lq_size: 64                      # LR: 64x64 -> HR: 128x128 (Training size)
    use_hflip: true
    use_rot: false                   # Disable rotation to save memory
    num_worker_per_gpu: 2            # Reduced from 6 to save memory
    batch_size_per_gpu: 6            # Reduced from 16 to fit VRAM
    accum_iter: 1                    # Keep at 1 for full training speed

  val:
    name: CC0_147k_Val_MemOpt
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_x2_bicubic_aa
    lq_size: 32                      # FIX: Smaller validation size to prevent attention OOM
    gt_size: 64                      # FIX: Smaller validation size to prevent attention OOM

network_g:
  type: paragonsr2

path:
  pretrain_network_g: ~
  strict_load_g: true
  resume_state: ~

train:
  ema_decay: 0.999
  ema_power: 0.75
  grad_clip: true

  optim_g:
    type: AdamW
    lr: !!float 2e-4
    weight_decay: !!float 1e-4
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [20000, 30000]
    gamma: 0.5

  total_iter: 40000
  warmup_iter: 500

  # Dynamic Loss Scheduling - prevents loss dominance and improves stability
  dynamic_loss_scheduling:
    enabled: true
    momentum: 0.92                    # Lower smoothing to respond faster
    adaptation_rate: 0.01             # Faster adaptation for stability
    min_weight: 1e-6
    max_weight: 50.0                  # Conservative upper bound
    adaptation_threshold: 0.05        # Sensitivity to changes
    baseline_iterations: 150          # Shorter baseline
    enable_monitoring: true

  losses:
    - type: l1loss
      loss_weight: 1.0
    - type: ssimloss
      loss_weight: 0.05

  # CRITICAL: Validation-specific memory optimization
  val_batch_size: 1                   # FIX: Single image validation prevents attention OOM
  val_num_workers: 1                  # FIX: Minimal workers for validation
  val_prefetch_factor: 2              # FIX: Reduced prefetching
  val_pin_memory: false               # FIX: Disable pin_memory for validation

val:
  val_enabled: true
  val_freq: 1000                      # Every 1000 iterations
  save_img: false                     # Disable for faster validation

  metrics_enabled: true
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 4
    ssim:
      type: calculate_ssim
      crop_border: 4

logger:
  print_freq: 100
  save_checkpoint_freq: 20000
  save_checkpoint_format: safetensors
  use_tb_logger: true
