#########################################################################################
# ParagonSR2 Realtime Fidelity Config
# Optimized for highest PSNR/SSIM metrics with pure reconstruction (no sharpening)
#########################################################################################
name: 2xParagonSR2_Realtime_fidelity
scale: 2

# VRAM MANAGEMENT SYSTEM
auto_vram_management:
  enabled: true # Enable automatic VRAM management
  target_vram_usage: 0.85 # Target 85% VRAM usage (optimal balance of usage vs safety)
  safety_margin: 0.05 # Additional 5% safety margin

use_amp: true # Use Automatic Mixed Precision for faster training/lower VRAM
amp_bf16: true # BF16 (Brain Float 16) prevents overflow better than FP16
use_channels_last: true # Critical optimization for NVIDIA Tensor Cores
num_gpu: auto # Use all GPUs
use_compile: false # Compiles the model graph for faster execution (~20-30% speedup)

datasets:
  train:
    name: CC0_147k_Train
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/filtered_versions/cc0_c5_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/filtered_versions/cc0_c5_lr_x2

    # METRIC-OPTIMIZED PARAMETERS for RTX 3060 12GB (Auto-VRAM managed)
    # Aggressive settings for maximum PSNR/SSIM with lightweight realtime architecture
    lq_size: 256 # 256 patch size (512 output) provides excellent context for training
    batch_size_per_gpu: 64 # High initial batch size (64) ensures very stable gradient estimates
    num_worker_per_gpu: 8 # Sufficient workers to keep the GPU fed without CPU bottleneck
    accum_iter: 1 # Gradient accumulation not needed with large batch size
    prefetch_mode: cpu # Offloads data prefetching to CPU to save GPU memory
    pin_memory: false # Disabled to prevent pinned memory fragmentation on 12GB cards

    use_hflip: true # Augmentation: Horizontal Flip
    use_rot: true # Augmentation: Rotation

  val:
    name: CC0_147k_Val
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_x2_bicubic_aa

network_g:
  type: paragonsr2_realtime # The "Nano" variant
  # FIDELITY OPTIMIZATION: Pure reconstruction for highest PSNR/SSIM
  upsampler_alpha: 0.0 # 0.0 disables sharpening, forcing the model to learn pure reconstruction (best for metrics)
  detail_gain: 0.05 # Low gain (0.05) is appropriate for this lightweight model to prevent noise amplification
  use_content_aware: false # False is correct for Realtime: minimizes inference latency (Zero overhead)
  use_checkpointing: true # Gradients checkpointing allows fitting this larger batch/patch size in 12GB VRAM

path:
  pretrain_network_g: ~
  strict_load_g: true

train:
  ema_decay: 0.999 # High decay for smoother EMA model
  ema_power: 0.75
  grad_clip: true # Prevents gradients from exploding during training

  optim_g:
    type: AdamW
    lr: !!float 2e-4 # Standard learning rate for this architecture size
    weight_decay: !!float 1e-4 # Standard weight decay
    betas: [0.9, 0.99]

  scheduler:
    type: MultiStepLR
    milestones: [40000, 50000, 55000] # Late stage decay to settle weights after main convergence
    gamma: 0.5

  total_iter: 200000 # 200k steps is ample for the Realtime model to converge
  warmup_iter: 1000

  # DYNAMIC LOSS SCHEDULING WITH AUTO-CALIBRATION
  dynamic_loss_scheduling:
    enabled: true

  # TRAINING AUTOMATIONS
  training_automations:
    enabled: true
    IntelligentLearningRateScheduler:
      enabled: true

    DynamicBatchAndPatchSizeOptimizer:
      enabled: true
      target_vram_usage: 0.85
      safety_margin: 0.05
      adjustment_frequency: 100
      min_batch_size: 2
      max_batch_size: 64
      min_lq_size: 64
      max_lq_size: 256
      vram_history_size: 50

    IntelligentEarlyStopping:
      enabled: true
      patience: 10000
      min_improvement: 0.01
      monitor_metric: "val/psnr"
      convergence_threshold: 0.0001
      convergence_log_frequency: 500

    AdaptiveGradientClipping:
      enabled: true

  # OPTIMAL FIDELITY LOSS COMBINATION
  losses:
    - type: l1loss
      loss_weight: 1.0 # Pixel-wise accuracy loss
    - type: mssimloss
      loss_weight: 0.08 # Structural loss to align with human perception (SSIM)

val:
  val_enabled: true
  val_freq: 1000
  save_img: true

  metrics_enabled: true
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 4
    ssim:
      type: calculate_ssim
      crop_border: 4

logger:
  print_freq: 100
  save_checkpoint_freq: 10000
  save_checkpoint_format: safetensors
  use_tb_logger: true
