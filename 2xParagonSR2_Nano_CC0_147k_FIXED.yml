#########################################################################################
# ParagonSR2 Nano - CC0 147k Dataset (FIXED CONFIGURATION)
# Fixed: Gradient scaling, dynamic loss scheduling, AMP, LR schedule
#########################################################################################
name: 2xParagonSR2_Nano_CC0_147k_FIXED
scale: 2

use_amp: true
amp_bf16: true              # ✅ FIXED: Enable BF16 for better precision
use_channels_last: true
fast_matmul: true
num_gpu: auto
manual_seed: 1024

datasets:
  train:
    name: CC0_147k_Train
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/lr_x2_bicubic_aa
    lq_size: 128
    use_hflip: true
    use_rot: true
    num_worker_per_gpu: 8
    batch_size_per_gpu: 16
    accum_iter: 1

  val:
    name: CC0_147k_Val
    type: pairedimagedataset
    dataroot_gt: /home/phips/Documents/dataset/cc0/val_hr
    dataroot_lq: /home/phips/Documents/dataset/cc0/val_lr_x2_bicubic_aa

network_g:
  type: paragonsr2_nano

path:
  pretrain_network_g: ~
  strict_load_g: true
  resume_state: ~

train:
  ema_decay: 0.999
  ema_power: 0.75
  grad_clip: true                   # ✅ CORRECT: Uses clip_grad_norm_(..., 1.0)

  optim_g:
    type: AdamW
    lr: !!float 2e-4
    weight_decay: !!float 1e-4
    betas: [0.9, 0.99]

  # ✅ FIXED: MultiStepLR compatible with EMA (not CosineAnnealingLR)
  scheduler:
    type: MultiStepLR
    milestones: [30000, 35000]      # Later milestones for EMA stability
    gamma: 0.5

  total_iter: 40000
  warmup_iter: 1000                 # ✅ Longer warmup for stability

  dynamic_loss_scheduling:
    enabled: true
    auto_calibrate: true

  losses:
    - type: l1loss
      loss_weight: 1.0
    - type: ssimloss
      loss_weight: 0.05

val:
  val_enabled: true
  val_freq: 1000
  save_img: false

  metrics_enabled: true
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 4
    ssim:
      type: calculate_ssim
      crop_border: 4

logger:
  print_freq: 100
  save_checkpoint_freq: 20000
  save_checkpoint_format: safetensors
  use_tb_logger: true
